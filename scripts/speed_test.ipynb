{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbaafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import statistics\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Dict, List, Tuple\n",
    "import ssl\n",
    "from urllib.parse import urlparse\n",
    "import socket\n",
    "import dns.resolver\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d2c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='speed_test.log'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ae6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebsiteSpeedTester:\n",
    "    def __init__(self, urls: List[str], num_requests: int = 5):\n",
    "        self.urls = [self._normalize_url(url) for url in urls]\n",
    "        self.num_requests = num_requests\n",
    "        self.results_df = pd.DataFrame()\n",
    "        self.unreachable_sites = []\n",
    "        logging.info(f\"Initialized tester with {len(urls)} URLs\")\n",
    "        \n",
    "    def _normalize_url(self, url: str) -> str:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = f'https://{url}'\n",
    "        logging.debug(f\"Normalized URL: {url}\")\n",
    "        return url\n",
    "\n",
    "    def is_website_reachable(self, url: str) -> bool:\n",
    "        logging.info(f\"Testing reachability for {url}\")\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        session = requests.Session()\n",
    "        urls_to_try = [url]\n",
    "        \n",
    "        if url.startswith('https://'):\n",
    "            urls_to_try.append('http://' + url[8:])\n",
    "        \n",
    "        for test_url in urls_to_try:\n",
    "            try:\n",
    "                logging.debug(f\"Attempting connection to {test_url}\")\n",
    "                response = session.get(\n",
    "                    test_url,\n",
    "                    headers=headers,\n",
    "                    timeout=10,\n",
    "                    allow_redirects=True,\n",
    "                    stream=True\n",
    "                )\n",
    "                response.close()\n",
    "                \n",
    "                if 200 <= response.status_code < 400:\n",
    "                    logging.info(f\"Successfully reached {test_url} (Status: {response.status_code})\")\n",
    "                    return True\n",
    "                    \n",
    "            except (requests.RequestException, socket.error, ssl.SSLError) as e:\n",
    "                logging.warning(f\"Failed to reach {test_url}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        logging.error(f\"Website unreachable: {url}\")\n",
    "        return False\n",
    "        \n",
    "    def _measure_dns(self, domain: str) -> Tuple[float, bool, str]:\n",
    "        logging.info(f\"Performing DNS lookup for {domain}\")\n",
    "        try:\n",
    "            start = time.time()\n",
    "            dns.resolver.resolve(domain, 'A')\n",
    "            duration = time.time() - start\n",
    "            logging.info(f\"DNS lookup successful for {domain} ({duration:.3f}s)\")\n",
    "            return duration, True, \"\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"DNS lookup failed for {domain}: {str(e)}\")\n",
    "            return 0, False, f\"DNS resolution failed: {str(e)}\"\n",
    "        \n",
    "    def _test_single_url(self, url: str) -> Dict:\n",
    "        logging.info(f\"\\n{'='*50}\\nStarting test for {url}\")\n",
    "        \n",
    "        # Create/append header to CSV if it doesn't exist\n",
    "        if not os.path.exists('speed_test_results.csv'):\n",
    "            with open('speed_test_results.csv', 'w', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=['url', 'timestamp', 'dns_lookup', 'connection', \n",
    "                                                     'ttfb', 'download', 'total', 'status', 'error_message'])\n",
    "                writer.writeheader()\n",
    "        logging.info(f\"\\n{'='*50}\\nStarting test for {url}\")\n",
    "        \n",
    "        metrics = {\n",
    "            'url': url,\n",
    "            'timestamp': datetime.now(),\n",
    "            'dns_lookup': [],\n",
    "            'connection': [],\n",
    "            'ttfb': [],\n",
    "            'download': [],\n",
    "            'total': [],\n",
    "            'status': 'success',\n",
    "            'error_message': ''\n",
    "        }\n",
    "        \n",
    "        if not self.is_website_reachable(url):\n",
    "            metrics['status'] = 'failed'\n",
    "            metrics['error_message'] = 'Website unreachable'\n",
    "            self.unreachable_sites.append({'url': url, 'error': 'Website unreachable'})\n",
    "            return metrics\n",
    "            \n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        \n",
    "        dns_time, dns_success, dns_error = self._measure_dns(domain)\n",
    "        if not dns_success:\n",
    "            metrics['status'] = 'failed'\n",
    "            metrics['error_message'] = dns_error\n",
    "            self.unreachable_sites.append({'url': url, 'error': dns_error})\n",
    "            return metrics\n",
    "        \n",
    "        logging.info(f\"Starting {self.num_requests} requests for {url}\")\n",
    "        for i in range(self.num_requests):\n",
    "            logging.info(f\"Request {i+1}/{self.num_requests} for {url}\")\n",
    "            try:\n",
    "                headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "                }\n",
    "                \n",
    "                metrics['dns_lookup'].append(dns_time)\n",
    "                start_time = time.time()\n",
    "                \n",
    "                with requests.Session() as session:\n",
    "                    conn_start = time.time()\n",
    "                    response = session.get(url, headers=headers, stream=True, timeout=10, verify=False, allow_redirects=True)\n",
    "                    conn_time = time.time() - conn_start\n",
    "                    \n",
    "                    if not (200 <= response.status_code < 400):\n",
    "                        raise requests.RequestException(f\"Invalid status code: {response.status_code}\")\n",
    "                        \n",
    "                    end_time = time.time()\n",
    "                    total_time = end_time - start_time\n",
    "                    download_time = total_time - conn_time\n",
    "                    \n",
    "                    metrics['connection'].append(conn_time)\n",
    "                    metrics['download'].append(download_time)\n",
    "                    metrics['total'].append(total_time)\n",
    "                    metrics['ttfb'].append(response.elapsed.total_seconds())\n",
    "                    \n",
    "                    logging.debug(f\"Request {i+1} metrics for {url}:\")\n",
    "                    logging.debug(f\"Connection: {conn_time:.3f}s\")\n",
    "                    logging.debug(f\"Download: {download_time:.3f}s\")\n",
    "                    logging.debug(f\"Total: {total_time:.3f}s\")\n",
    "                    \n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during request {i+1} for {url}: {str(e)}\")\n",
    "                if i == 0:\n",
    "                    metrics['status'] = 'failed'\n",
    "                    metrics['error_message'] = str(e)\n",
    "                    self.unreachable_sites.append({'url': url, 'error': str(e)})\n",
    "                    break\n",
    "                \n",
    "        # Calculate averages for successful metrics\n",
    "        for key in ['dns_lookup', 'connection', 'ttfb', 'download', 'total']:\n",
    "            if metrics[key]:\n",
    "                metrics[key] = statistics.mean(metrics[key])\n",
    "                logging.info(f\"Average {key} for {url}: {metrics[key]:.3f}s\")\n",
    "            else:\n",
    "                metrics[key] = None\n",
    "                \n",
    "        logging.info(f\"Completed testing {url}\\n{'='*50}\")\n",
    "        \n",
    "        # Write results immediately to CSV\n",
    "        with open('speed_test_results.csv', 'a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['url', 'timestamp', 'dns_lookup', 'connection', \n",
    "                                                 'ttfb', 'download', 'total', 'status', 'error_message'])\n",
    "            writer.writerow(metrics)\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "    def run_test(self, max_workers: int = 3) -> pd.DataFrame:\n",
    "        logging.info(f\"Starting batch test with {max_workers} workers\")\n",
    "        all_results = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            results = list(executor.map(self._test_single_url, self.urls))\n",
    "            all_results.extend(results)\n",
    "            \n",
    "        self.results_df = pd.DataFrame(all_results)\n",
    "        logging.info(\"Batch test completed\")\n",
    "        return self.results_df\n",
    "        \n",
    "    def save_results(self, filename: str = 'speed_test_results.csv'):\n",
    "        if not self.results_df.empty:\n",
    "            self.results_df.to_csv(filename, index=False)\n",
    "            logging.info(f\"Results saved to {filename}\")\n",
    "            \n",
    "        if self.unreachable_sites:\n",
    "            unreachable_df = pd.DataFrame(self.unreachable_sites)\n",
    "            unreachable_df.to_csv('unreachable_sites.csv', index=False)\n",
    "            logging.info(f\"Unreachable sites saved to unreachable_sites.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    websites = pd.read_csv(\"../data/us_gov_domain_list.csv\", usecols=[\"Domain name\"]).drop_duplicates()\n",
    "    websites = websites[\"Domain name\"].dropna().astype(str).tolist()\n",
    "    try:\n",
    "        logging.info(\"Starting speed test script\")\n",
    "        tester = WebsiteSpeedTester(websites)\n",
    "        \n",
    "        results_df = tester.run_test()\n",
    "        \n",
    "        print(\"\\nResults Summary:\")\n",
    "        print(f\"Total sites tested: {len(websites)}\")\n",
    "        print(f\"Successful: {len(results_df[results_df['status'] == 'success'])}\")\n",
    "        print(f\"Failed: {len(results_df[results_df['status'] == 'failed'])}\")\n",
    "        \n",
    "        print(\"\\nDetailed Results (in seconds):\")\n",
    "        print(results_df[['url', 'status', 'error_message'] + \n",
    "                        [col for col in results_df.columns if col not in \n",
    "                         ['url', 'status', 'error_message', 'timestamp']]].round(3))\n",
    "        \n",
    "        tester.save_results()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Script error: {str(e)}\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd293ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
